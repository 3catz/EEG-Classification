{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating training data...\n",
      "Processing session:  data/ML101_KS.csv . ( 1  of  16 )\n",
      "468  frames generated with label  1 .468Interpolating 137/468Interpolating 212/468Interpolating 351/468Interpolating 423/468\n",
      "\n",
      "\n",
      "Processing session:  data/ML101_US.csv . ( 2  of  16 )\n",
      "448  frames generated with label  0 .448Interpolating 137/448Interpolating 278/448Interpolating 423/448\n",
      "\n",
      "\n",
      "Processing session:  data/ML102_KS.csv . ( 3  of  16 )\n",
      "444  frames generated with label  1 .444Interpolating 136/444Interpolating 202/444Interpolating 266/444Interpolating 335/444\n",
      "\n",
      "\n",
      "Processing session:  data/ML102_US.csv . ( 4  of  16 )\n",
      "436  frames generated with label  0 .7/436Interpolating 222/436Interpolating 369/436Interpolating 435/436\n",
      "\n",
      "\n",
      "Processing session:  data/ML103_KS.csv . ( 5  of  16 )\n",
      "Interpolating 452/452nterpolating 65/452Interpolating 132/452Interpolating 195/452Interpolating 258/452Interpolating 331/452Interpolating 390/452452  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML103_US.csv . ( 6  of  16 )\n",
      "416  frames generated with label  0 .7/416Interpolating 193/416Interpolating 324/416Interpolating 390/416\n",
      "\n",
      "\n",
      "Processing session:  data/ML104_KS.csv . ( 7  of  16 )\n",
      "404  frames generated with label  1 .404Interpolating 149/404Interpolating 211/404Interpolating 346/404\n",
      "\n",
      "\n",
      "Processing session:  data/ML104_US.csv . ( 8  of  16 )\n",
      "408  frames generated with label  0 .408Interpolating 207/408Interpolating 278/408Interpolating 343/408\n",
      "\n",
      "\n",
      "Processing session:  data/ML105_KS.csv . ( 9  of  16 )\n",
      "428  frames generated with label  1 .428Interpolating 147/428Interpolating 220/428Interpolating 292/428Interpolating 359/428Interpolating 420/428\n",
      "\n",
      "\n",
      "Processing session:  data/ML105_US.csv . ( 10  of  16 )\n",
      "452  frames generated with label  0 .452Interpolating 88/452Interpolating 138/452Interpolating 186/452Interpolating 240/452Interpolating 309/452Interpolating 378/452Interpolating 446/452\n",
      "\n",
      "\n",
      "Processing session:  data/ML106_KS.csv . ( 11  of  16 )\n",
      "460  frames generated with label  1 .460Interpolating 134/460Interpolating 203/460Interpolating 269/460Interpolating 331/460Interpolating 399/460\n",
      "\n",
      "\n",
      "Processing session:  data/ML106_US.csv . ( 12  of  16 )\n",
      "556  frames generated with label  0 .556Interpolating 129/556Interpolating 196/556Interpolating 248/556Interpolating 307/556Interpolating 366/556Interpolating 434/556Interpolating 499/556\n",
      "\n",
      "\n",
      "Processing session:  data/ML107_KS.csv . ( 13  of  16 )\n",
      "492  frames generated with label  1 .492Interpolating 214/492Interpolating 272/492Interpolating 333/492Interpolating 449/492\n",
      "\n",
      "\n",
      "Processing session:  data/ML107_US.csv . ( 14  of  16 )\n",
      "472  frames generated with label  0 .472Interpolating 131/472Interpolating 190/472Interpolating 252/472Interpolating 389/472Interpolating 437/472\n",
      "\n",
      "\n",
      "Processing session:  data/ML108_KS.csv . ( 15  of  16 )\n",
      "Interpolating 480/480nterpolating 68/480Interpolating 140/480Interpolating 208/480Interpolating 346/480Interpolating 419/480480  frames generated with label  1 .\n",
      "\n",
      "\n",
      "Processing session:  data/ML108_US.csv . ( 16  of  16 )\n",
      "Interpolating 468/468nterpolating 72/468Interpolating 144/468Interpolating 216/468Interpolating 278/468Interpolating 341/468Interpolating 404/468468  frames generated with label  0 .\n",
      "\n",
      "\n",
      "x_train shape: (5827, 28, 28, 3)\n",
      "5827 train samples\n",
      "1457 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 11, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 22        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 28,992\n",
      "Trainable params: 28,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#train_pipeline\n",
    "from eeg_learn_functions import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as scs\n",
    "import re\n",
    "from numpy import genfromtxt\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.precision = 4\n",
    "\n",
    "theta = (4,8)\n",
    "alpha = (8,12)\n",
    "beta = (12,40)\n",
    "\n",
    "def get_fft(snippet):\n",
    "    Fs = 128.0;  # sampling rate\n",
    "    #Ts = len(snippet)/Fs/Fs; # sampling interval\n",
    "    snippet_time = len(snippet)/Fs\n",
    "    Ts = 1.0/Fs; # sampling interval\n",
    "    t = np.arange(0,snippet_time,Ts) # time vector\n",
    "\n",
    "    # ff = 5;   # frequency of the signal\n",
    "    # y = np.sin(2*np.pi*ff*t)\n",
    "    y = snippet\n",
    "#     print('Ts: ',Ts)\n",
    "#     print(t)\n",
    "#     print(y.shape)\n",
    "    n = len(y) # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n/Fs\n",
    "    frq = k/T # two sides frequency range\n",
    "    frq = frq[range(n//2)] # one side frequency range\n",
    "\n",
    "    Y = np.fft.fft(y)/n # fft computing and normalization\n",
    "    Y = Y[range(n//2)]\n",
    "    #Added in: (To remove bias.)\n",
    "    #Y[0] = 0\n",
    "    return frq,abs(Y)\n",
    "\n",
    "def theta_alpha_beta_averages(f,Y):\n",
    "    theta_range = (4,8)\n",
    "    alpha_range = (8,12)\n",
    "    beta_range = (12,40)\n",
    "    theta = Y[(f>theta_range[0]) & (f<=theta_range[1])].mean()\n",
    "    alpha = Y[(f>alpha_range[0]) & (f<=alpha_range[1])].mean()\n",
    "    beta = Y[(f>beta_range[0]) & (f<=beta_range[1])].mean()\n",
    "    return theta, alpha, beta\n",
    "\n",
    "def make_steps(samples,frame_duration,overlap):\n",
    "    '''\n",
    "    in:\n",
    "    samples - number of samples in the session\n",
    "    frame_duration - frame duration in seconds\n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "\n",
    "    out: list of tuple ranges\n",
    "    '''\n",
    "    #steps = np.arange(0,len(df),frame_length)\n",
    "    Fs = 128\n",
    "    i = 0\n",
    "    intervals = []\n",
    "    samples_per_frame = Fs * frame_duration\n",
    "    while i+samples_per_frame <= samples:\n",
    "        intervals.append((i,i+samples_per_frame))\n",
    "        i = i + samples_per_frame - int(samples_per_frame*overlap)\n",
    "    return intervals\n",
    "\n",
    "def make_frames(df,frame_duration):\n",
    "    '''\n",
    "    in: dataframe or array with all channels, frame duration in seconds\n",
    "    out: array of theta, alpha, beta averages for each probe for each time step\n",
    "        shape: (n-frames,m-probes,k-brainwave bands)\n",
    "    '''\n",
    "    Fs = 128.0\n",
    "    frame_length = Fs*frame_duration\n",
    "    frames = []\n",
    "    steps = make_steps(len(df),frame_duration,overlap)\n",
    "    for i,_ in enumerate(steps):\n",
    "        frame = []\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else:\n",
    "            for channel in df.columns:\n",
    "                snippet = np.array(df.loc[steps[i][0]:steps[i][1],int(channel)])\n",
    "                f,Y =  get_fft(snippet)\n",
    "                theta, alpha, beta = theta_alpha_beta_averages(f,Y)\n",
    "                frame.append([theta, alpha, beta])\n",
    "\n",
    "        frames.append(frame)\n",
    "    return np.array(frames)\n",
    "\n",
    "locs_2d = [(-2.0,4.0),\n",
    "           (2.0,4.0),\n",
    "           (-1.0,3.0),\n",
    "           (1.0,3.0),\n",
    "           (-3.0,3.0),\n",
    "           (3.0,3.0),\n",
    "           (-2.0,2.0),\n",
    "           (2.0,2.0),\n",
    "           (-2.0,-2.0),\n",
    "           (2.0,-2.0),\n",
    "           (-4.0,1.0),\n",
    "           (4.0,1.0),\n",
    "           (-1.0,-3.0),\n",
    "           (1.0,-3.0)]\n",
    "\n",
    "def make_data_pipeline(file_names,labels,image_size,frame_duration,overlap):\n",
    "    '''\n",
    "    IN:\n",
    "    file_names - list of strings for each input file (one for each subject)\n",
    "    labels - list of labels for each\n",
    "    image_size - int size of output images in form (x, x)\n",
    "    frame_duration - time length of each frame (seconds)\n",
    "    overlap - float fraction of frame to overlap in range (0,1)\n",
    "\n",
    "    OUT:\n",
    "    X: np array of frames (unshuffled)\n",
    "    y: np array of label for each frame (1 or 0)\n",
    "    '''\n",
    "\n",
    "    Fs = 128.0   #sampling rate\n",
    "    frame_length = Fs * frame_duration\n",
    "\n",
    "    print('Generating training data...')\n",
    "\n",
    "\n",
    "    for i, file in enumerate(file_names):\n",
    "        print ('Processing session: ',file, '. (',i+1,' of ',len(file_names),')')\n",
    "        data = genfromtxt(file, delimiter=',').T\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        X_0 = make_frames(df,frame_duration)\n",
    "        #steps = np.arange(0,len(df),frame_length)\n",
    "        X_1 = X_0.reshape(len(X_0),14*3)\n",
    "\n",
    "        images = gen_images(np.array(locs_2d),X_1, image_size, normalize=False)\n",
    "        images = np.swapaxes(images, 1, 3)\n",
    "        print(len(images), ' frames generated with label ', labels[i], '.')\n",
    "        print('\\n')\n",
    "        if i == 0:\n",
    "            X = images\n",
    "            y = np.ones(len(images))*labels[0]\n",
    "        else:\n",
    "            X = np.concatenate((X,images),axis = 0)\n",
    "            y = np.concatenate((y,np.ones(len(images))*labels[i]),axis = 0)\n",
    "\n",
    "\n",
    "    return X,np.array(y)\n",
    "\n",
    "file_names = ['data/ML101_KS.csv',\n",
    "              'data/ML101_US.csv',\n",
    "              'data/ML102_KS.csv',\n",
    "              'data/ML102_US.csv',\n",
    "              'data/ML103_KS.csv',\n",
    "              'data/ML103_US.csv',\n",
    "              'data/ML104_KS.csv',\n",
    "              'data/ML104_US.csv',\n",
    "              'data/ML105_KS.csv',\n",
    "              'data/ML105_US.csv',\n",
    "              'data/ML106_KS.csv',\n",
    "              'data/ML106_US.csv',\n",
    "              'data/ML107_KS.csv',\n",
    "              'data/ML107_US.csv',\n",
    "              'data/ML108_KS.csv',\n",
    "              'data/ML108_US.csv']\n",
    "labels = [1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0]\n",
    "image_size = 28\n",
    "frame_duration = 1.0\n",
    "overlap = 0.75\n",
    "X, y = make_data_pipeline(file_names,labels,image_size,frame_duration,overlap)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20,shuffle=True)\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 500\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "#x_train /= 255\n",
    "#x_test /= 255\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
